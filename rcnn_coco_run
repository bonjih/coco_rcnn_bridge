import torch
import time

from datasets2 import (
    get_model_instance_segmentation,
    collate_fn,
    get_transform,
    Dataset,
)

if __name__ == "__main__":

    train_data_dir = "custom_data/train"
    train_coco = "custom_data/train/_annotations.coco.json"
    eval_dir = "custom_data/valid"
    train_batch_size = 5
    train_shuffle_dl = True
    num_workers_dl = 2
    num_classes = 5
    lr = .005
    momentum = .9
    weight_decay = .005
    num_epochs = 50
    save = "option_model"

    print("Torch version:", torch.__version__)

    dataset = Dataset(
        root=train_data_dir, annotation=train_coco, transforms=get_transform()
    )

    data_loader = torch.utils.data.DataLoader(
        dataset,
        batch_size=train_batch_size,
        shuffle=train_shuffle_dl,
        num_workers=num_workers_dl,
        collate_fn=collate_fn,
    )

    device = torch.device("cuda") if torch.cuda.is_available() else torch.device("cpu")

    print("device: ", device)

    contest_detector = get_model_instance_segmentation(num_classes)
    contest_detector.to(device)

    # parameters
    params = [p for p in contest_detector.parameters() if p.requires_grad]
    optimizer = torch.optim.SGD(
        params, lr=lr, momentum=momentum, weight_decay=weight_decay
    )

    len_dataloader = len(data_loader)
    best_loss = float('inf')  # Initialize with a large value for loss
    best_model_path = None

    for epoch in range(num_epochs):
        print(f"Epoch: {epoch + 1}/{num_epochs}")
        start = time.time()
        contest_detector.train()
        predictions = []
        targets = []

        i = 0
        total_losses = 0.0

        for imgs, annotations in data_loader:
            i += 1
            imgs = list(img.to(device) for img in imgs)
            annotations = [{k: v.to(device) for k, v in t.items()} for t in annotations]
            loss_dict = contest_detector(imgs, annotations)
            losses = sum(loss for loss in loss_dict.values())
            total_losses += losses.item()

            optimizer.zero_grad()
            losses.backward()
            optimizer.step()

            # with torch.no_grad():
            #     for img, annotation in zip(imgs, annotations):
            #         print(img)
            #         model_output = contest_detector([img])  # Pass the image as a list to get predictions
            #         # predictions.append(model_output[0])  # Append the first (and only) prediction to predictions list
            #         # targets.append(annotation)

            #print(f"Iteration: {i}/{len_dataloader}, Loss: {losses}, Time: {time.time() - start}s")

        # Compute the average loss for the epoch
        average_loss = total_losses / len_dataloader

        # Save the model if the current loss is better than the previous best
        if average_loss < best_loss:
            best_loss = average_loss
            best_model_path = f"{save}_best.pth"
            torch.save(contest_detector.state_dict(), best_model_path)
            print("Best model saved at:", best_model_path)

    # Save the final model
    torch.save(contest_detector.state_dict(), f"{save}_final.pth")
